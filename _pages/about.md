---
permalink: /
title: "Hi，this is Jack"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am Songxin Qu (Jack), a dedicated AI Engineer and Software Developer specializing in large language models (LLMs). With a strong foundation in software engineering and ongoing graduate studies at the University of Science and Technology of China, I focus on advancing LLM research, fine-tuning, and scalable deployment. My work bridges cutting-edge AI advancements with robust full-stack development, leveraging frameworks like PyTorch, Hugging Face Transformers, and distributed training tools to deliver high-impact solutions.

Technical Expertise
======
My core strengths lie in LLM fine-tuning, model optimization, and end-to-end AI system design. I excel in adapting foundational models (e.g., GPT, LLaMA) for domain-specific tasks through parameter-efficient techniques like LoRA and QLoRA, achieving performance improvements while minimizing computational costs. My experience spans:
1. Custom LLM Development: Fine-tuning models for specialized NLP tasks using frameworks like DeepSpeed and PyTorch Lightning, with a focus on low-rank adaptation and quantization.
2. Distributed Training: Optimizing training pipelines for multi-GPU/TPU environments, leveraging Megatron-LM and NVIDIA NeMo for efficient large-scale parallelism.
3. Deployment & Scalability: Containerizing LLM inference services with Docker, designing RESTful APIs for seamless integration, and deploying latency-sensitive applications using vLLM or TensorRT-LLM.
4. Evaluation & Alignment: Implementing rigorous evaluation metrics (BLEU, ROUGE) and alignment strategies (RLHF, DPO) to ensure model robustness and ethical compliance.

Career Vision
======
I am driven to push the boundaries of generative AI by solving complex challenges in model efficiency, multi-modal integration, and real-time inference. Whether refining billion-parameter models for industry-specific use cases or architecting MLOps pipelines for continuous learning, I aim to deliver solutions that balance technical rigor with practical usability. My goal is to contribute to open-source LLM ecosystems while advancing enterprise-grade AI applications in fields like healthcare, finance, and autonomous systems.

Featured Projects
------
1. Domain-Specific LLM Fine-tuning: Adapted LLaMA-2 for a legal document analysis system, reducing hallucination rates by 18% through curated datasets and RLHF.
2. Efficient Training Pipelines: Built a distributed fine-tuning framework using Hugging Face Accelerate, achieving 2.3x faster convergence on proprietary datasets.
3. Edge LLM Deployment: Optimized a Mistral-7B variant for real-time inference on NVIDIA Jetson platforms, achieving 45ms/token latency via TensorRT-LLM.

Let’s Connect
------
For collaborations or discussions on LLMs, AI infrastructure, or full-stack AI systems, reach me at QSXJACK@QQ.COM or explore my work at QSXJACK.INFO. Dive deeper into my projects on [GitHub]([https://qsxustc.](https://github.com/qsxustc)).
